<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Blog of Bernardas Ališauskas - code</title><link href="https://granitosaurus.github.io/" rel="alternate"></link><link href="Blog%20of%20Bernardas%20Ali%C5%A1auskas/feeds/code.atom.xml" rel="self"></link><id>https://granitosaurus.github.io/</id><updated>2018-12-10T00:00:00+01:00</updated><subtitle>Python programmer and a goof who loves free software, video-games and heavy metal</subtitle><entry><title>Diving Into Web-Crawling</title><link href="https://granitosaurus.github.io/starting-to-crawl.html" rel="alternate"></link><published>2018-12-10T00:00:00+01:00</published><updated>2018-12-10T00:00:00+01:00</updated><author><name>Bernardas Ališauskas</name></author><id>tag:granitosaurus.github.io,2018-12-10:/starting-to-crawl.html</id><summary type="html">&lt;p&gt;Where to start with the art of hoarding online data?&lt;/p&gt;</summary><content type="html">&lt;p&gt;Web crawling is a brilliant source to bootstrap your application. Almost every application requires data of some sort and why not just pick up some public data available on the world wide web!&lt;/p&gt;
&lt;p&gt;In this introduction I'll cover the core ideas behind web-crawling and web-crawling with python.&lt;/p&gt;
&lt;h1 id="what's web crawling?"&gt;What's Web Crawling?&lt;/h1&gt;
&lt;p&gt;First it's important to wrap your head around the stages of web crawling program.  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;crawler&lt;/strong&gt; or &lt;strong&gt;spider&lt;/strong&gt;
A program that connects to web pages and downloads their contents. &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To put it simply it's a program that goes online and finds two things:  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;data the user is looking for.  &lt;/li&gt;
&lt;li&gt;more targets to crawl &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;e.g.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Go to http://shop.com&lt;/li&gt;
&lt;li&gt;Find product pages&lt;/li&gt;
&lt;li&gt;Find and download product data such as price, title, description&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="stages"&gt;Stages&lt;/h1&gt;
&lt;p&gt;&lt;a href="/images/crawl-loop.png"&gt;&lt;img src="/images/crawl-loop.png" title="this is very cool"/&gt;&lt;/a&gt;&lt;figcaption&gt;this is very cool&lt;/figcaption&gt;&lt;/p&gt;
&lt;p&gt;A usual web-crawler program will be made from 4 core stages:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Discovery - find product urls to crawl&lt;/li&gt;
&lt;li&gt;Consumer - consume product urls and retrieve their htmls&lt;/li&gt;
&lt;li&gt;Parser - parse html data into something useful&lt;/li&gt;
&lt;li&gt;Processor - process the data with pipeline, filters etc.&lt;/li&gt;
&lt;li&gt;Loop!&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;note: these stages don't have to have to happen in strict order&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;There can be few more steps in between but the core logic of a web crawler looks like this:&lt;/p&gt;
&lt;p&gt;&lt;img alt="basic crawler" src="https://granitosaurus.github.io/images/crawling.png"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;worth noting that websites can return all sorts of content not only html. Some return json, some just text and some code like javascript.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In very simplest python pseudo code for a crawler would look like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'https://www.python.org/jobs/'&lt;/span&gt;

&lt;span class="n"&gt;job_urls&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;find_job_urls&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;consume&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;job_urls&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;process&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;json&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'output.json'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s1"&gt;'w'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dumps&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can find full crawler at the end of blog post.&lt;/p&gt;
&lt;h1 id="crawling"&gt;Crawling&lt;/h1&gt;
&lt;p&gt;There are two ways to crawl http urls: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Synchronous - slow and simple &lt;/li&gt;
&lt;li&gt;Asynchronous - complex but blazing fast.  &lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Which one to use?&lt;/strong&gt; As beginner or if you don't need speed stick with synchronous approach. The programming is much more simple and easier to debug. However asynchronous knowledge is very valuable and learning it is a great idea&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id="synchronous"&gt;Synchronous&lt;/h2&gt;
&lt;p&gt;This is very straight-forward approach. Everything goes in your program's order: &lt;/p&gt;
&lt;p&gt;&lt;img alt="basic crawl loop" src="https://granitosaurus.github.io/images/crawl-loop.png"/&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;for every url: download page -&amp;gt; parse it -&amp;gt; store it -&amp;gt; repeat&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;For synchronous crawling most popular library is &lt;a href="http://docs.python-requests.org/en/master/"&gt;requests&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;However while this approach is simple and easy to maintain it ends up being very slow as every time program connects to a webpage to download data program need to wait for it to response - in the mean time program could be doing something else: like download &lt;em&gt;another&lt;/em&gt; webpage, parse the data or store it.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;when is synchronous approach good enough?&lt;/strong&gt; Often a lot of applications don't need to retrieve a lot of data (e.g. football match score crawler) then sync code is more than enough. &lt;br/&gt;
Alternatively a lot of website have request limits that are high enough that match synchronous code slowness. &lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id="asynchronous"&gt;Asynchronous&lt;/h2&gt;
&lt;p&gt;Async programming is a bit more complex to wrap your head around but to put it shortly it allows the code to be executed in pararel.  &lt;/p&gt;
&lt;p&gt;Your program can schedule 100 request to a website &lt;em&gt;at once&lt;/em&gt; and handle response as they come in or do something else!  &lt;/p&gt;
&lt;p&gt;&lt;img alt="async crawl loop" src="https://granitosaurus.github.io/images/crawl-loop-async.png"/&gt;&lt;/p&gt;
&lt;p&gt;So it terms of speed it vastly outperforms synchronous crawlers as they don't have to wait!&lt;/p&gt;
&lt;p&gt;&lt;img alt="basic crawler" src="https://granitosaurus.github.io/images/sync_v_async.png"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;"checking" square here is very simplified representation of async mechanism&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;For asynchronous crawling there are a lot of choices and no clear defacto standards. I recommend &lt;a href="https://github.com/ross/requests-futures"&gt;requests-futures&lt;/a&gt; for caroutine based approach and &lt;a href="https://twistedmatrix.com/"&gt;twisted&lt;/a&gt; or &lt;a href="https://github.com/twisted/treq"&gt;treq&lt;/a&gt; for callback based approach.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;caroutines or callbacks?&lt;/strong&gt; While caroutines are much more favored async principle these days callbacks have a special place in web-crawling community as the logic tends to match scraping patterns better&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id="parsing_1"&gt;Parsing&lt;/h1&gt;
&lt;p&gt;There are all sorts of data types on the web, but most likely you're either will be crawling &lt;code&gt;html&lt;/code&gt; or &lt;code&gt;json&lt;/code&gt;. &lt;/p&gt;
&lt;h2 id="html"&gt;Html&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;Html&lt;/code&gt; is a subset of xml tree structures. It's a great data type for representing structure, however it's not a great data type for representing data itself.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="nt"&gt;&amp;lt;html&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;body&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;div&lt;/span&gt; &lt;span class="na"&gt;id=&lt;/span&gt;&lt;span class="s"&gt;name&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt; rubber chicken &lt;span class="nt"&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;div&lt;/span&gt; &lt;span class="na"&gt;id=&lt;/span&gt;&lt;span class="s"&gt;price&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt; 55.99 &lt;span class="nt"&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;/body&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;/html&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;So usually this data is either converted to database tables or json, csv documents:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;csv documents:  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;name,price   &lt;/span&gt;
&lt;span class="err"&gt;rubber chicken, 55.99&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;json documents:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;[&lt;/span&gt;
&lt;span class="err"&gt;    {&lt;/span&gt;
&lt;span class="err"&gt;        "name": "rubber chicken",&lt;/span&gt;
&lt;span class="err"&gt;        "price": 55.99&lt;/span&gt;
&lt;span class="err"&gt;    } &lt;/span&gt;
&lt;span class="err"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;database tables&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;------------------------------&lt;/span&gt;
&lt;span class="err"&gt;|       name       |  price  |&lt;/span&gt;
&lt;span class="err"&gt;------------------------------&lt;/span&gt;
&lt;span class="err"&gt;|  rubber chicken  |  55.99  |&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;What data type to chose for output?&lt;/strong&gt; Anything works! However some data types are easier to work than others. &lt;code&gt;json&lt;/code&gt; is an easy to format to work with as it translates to python &lt;code&gt;dict&lt;/code&gt; seamlessly. &lt;code&gt;csv&lt;/code&gt; is great to work with as it's an easy format to write and parse. &lt;code&gt;json-lines&lt;/code&gt; format is best of both worlds. 
&lt;strong&gt;What about data bases?&lt;/strong&gt; Document based databases are often preferred when web-scraping. Like &lt;a href="https://www.mongodb.com/"&gt;MongoDB&lt;/a&gt; and &lt;a href="http://couchdb.apache.org/"&gt;couchDB&lt;/a&gt;, they are great for storing json data, while relation databases are a bit less straight-forward but come with their own benefits (like &lt;a href="https://sqlite.org/index.html"&gt;sqlite&lt;/a&gt; and &lt;a href="https://mariadb.org/"&gt;mariadb&lt;/a&gt;)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="parsing html"&gt;Parsing html&lt;/h3&gt;
&lt;p&gt;Since html is a structural data type we can parse it quite easily. For that there are &lt;a href="https://www.w3schools.com/xml/xpath_intro.asp"&gt;xpath&lt;/a&gt; and &lt;a href="https://www.w3schools.com/csSref/css_selectors.asp"&gt;css&lt;/a&gt; selectors and appropriate python libraries that implement this selector logic.&lt;/p&gt;
&lt;p&gt;For python all you need is &lt;a href="https://github.com/scrapy/parsel"&gt;parsel&lt;/a&gt; which allows you to use both types of selectors to parse data. Alternatively you can also use a popular alternative &lt;a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/"&gt;beautifulsoup4&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Here's a &lt;code&gt;parsel&lt;/code&gt; example:  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;parsel&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Selector&lt;/span&gt;

&lt;span class="n"&gt;html&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"""&lt;/span&gt;
&lt;span class="s2"&gt;    &amp;lt;html&amp;gt;&lt;/span&gt;
&lt;span class="s2"&gt;        &amp;lt;body&amp;gt;&lt;/span&gt;
&lt;span class="s2"&gt;            &amp;lt;div id=name&amp;gt; rubber chicken &amp;lt;/div&amp;gt;&lt;/span&gt;
&lt;span class="s2"&gt;            &amp;lt;div id=price&amp;gt; 55.99 &amp;lt;/div&amp;gt;&lt;/span&gt;
&lt;span class="s2"&gt;        &amp;lt;/body&amp;gt;&lt;/span&gt;
&lt;span class="s2"&gt;    &amp;lt;/html&amp;gt;&lt;/span&gt;
&lt;span class="s2"&gt;"""&lt;/span&gt;
&lt;span class="n"&gt;selector&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Selector&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;html&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# css selector&lt;/span&gt;
&lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;selector&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;css&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'#name::text'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extract_first&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="c1"&gt;# xpath selector&lt;/span&gt;
&lt;span class="n"&gt;price&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;selector&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'//div[@id="price"]/text()'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extract_first&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;price&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# ' 55.99 ',' rubber chicken '&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Surprisingly simple!&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Which one, css or xpath?&lt;/strong&gt;
Generally css selectors are much easier and more bautiful but xpath selectors are much powerful. So ideally use css and fallback to xpath when encountering something more complicated.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Parsing with regex?&lt;/strong&gt;
Generally parsing html with regex is a bad idea as regex patterns will quickly become unreliable. Html is structure data type - embrace it!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id="json_1"&gt;Json&lt;/h2&gt;
&lt;p&gt;This type of data is often used by website internally together with javascript. Sometimes you can crawl these pages directly either through public or internal websites API. &lt;/p&gt;
&lt;p&gt;It's super convenient as you don't need to do any parsing yourself! &lt;/p&gt;
&lt;h4 id="parsing json"&gt;Parsing json&lt;/h4&gt;
&lt;p&gt;Parsing json is super easy as it can be read as python dictionary right out of the box:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;json&lt;/span&gt;
&lt;span class="n"&gt;json_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'{"data": [{"name": "product", "price": 55.99}]}'&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loads&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;json_data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'data'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'price'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="c1"&gt;# 55.99&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;em&gt;These days more and more web pages become dependant on javascript thus often providing json data&lt;/em&gt;&lt;/p&gt;
&lt;h1 id="synchronous example_2"&gt;Synchronous Example&lt;/h1&gt;
&lt;p&gt;Lets write a simple article crawler for python blog posts!&lt;/p&gt;
&lt;p&gt;for this we'll use &lt;a href="https://github.com/scrapy/parsel"&gt;parsel&lt;/a&gt; and &lt;a href="http://docs.python-requests.org/en/master/"&gt;requests&lt;/a&gt; packages. You can get them via pip:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;pip install parsel requests&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Our spider logic would follow:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Go to page with all links to blog posts&lt;/li&gt;
&lt;li&gt;Go to every blog post&lt;/li&gt;
&lt;li&gt;Extract data&lt;/li&gt;
&lt;li&gt;Store data to file&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;json&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;urllib.parse&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;urljoin&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;unquote&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;parsel&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Selector&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;requests&lt;/span&gt;

&lt;span class="n"&gt;session&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;  &lt;span class="c1"&gt;# 1&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;discover&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="sd"&gt;"""Discover job urls in jobs listing page"""&lt;/span&gt;
    &lt;span class="n"&gt;jobs_url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'https://www.python.org/jobs/'&lt;/span&gt;

    &lt;span class="n"&gt;jobs_html&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;jobs_url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;
    &lt;span class="n"&gt;jobs_sel&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Selector&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;jobs_html&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;urls&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;jobs_sel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;css&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'.listing-company-name a::attr(href)'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extract&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;urljoin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;jobs_url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;html&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""Parse job html"""&lt;/span&gt;
    &lt;span class="n"&gt;sel&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Selector&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;html&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;company&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;css&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'.listing-location a::text'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extract_first&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;email&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;css&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'.reference.external::attr(href)'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extract_first&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"//h2[contains(text(),'Job Title')]"&lt;/span&gt;
                      &lt;span class="s2"&gt;"/following-sibling::text()"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extract_first&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;''&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;description&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"//h2[contains(text(),'Job Title')]"&lt;/span&gt;
                            &lt;span class="s2"&gt;"/following-sibling::p/text()"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extract_first&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;''&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="s1"&gt;'url'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;'location'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;company&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;'title'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
        &lt;span class="s1"&gt;'description'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;description&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;'email'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;unquote&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;email&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;':'&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""Here usually you'd add extra processing steps&lt;/span&gt;
&lt;span class="sd"&gt;    like upload to database&lt;/span&gt;
&lt;span class="sd"&gt;    or adding crawl time&lt;/span&gt;
&lt;span class="sd"&gt;    or determening whether to drop results based on their values"""&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;consume&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""Consume job urls by downloading them, parsing data and saving to disk"""&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;'crawling job: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;html&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;
        &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="n"&gt;process&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;html&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;crawl&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="sd"&gt;    Complete crawl loop:&lt;/span&gt;
&lt;span class="sd"&gt;    1. Discover job listing urls&lt;/span&gt;
&lt;span class="sd"&gt;    2. parse html for data&lt;/span&gt;
&lt;span class="sd"&gt;    3. process data&lt;/span&gt;
&lt;span class="sd"&gt;    4. store data&lt;/span&gt;
&lt;span class="sd"&gt;    """&lt;/span&gt;
    &lt;span class="n"&gt;urls&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;discover&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;consume&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'collected.json'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'w'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dumps&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;indent&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;


&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;'__main__'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;crawl&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As you can see the crawler is split into 4 parts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Discovery - discover job urls in listing page&lt;/li&gt;
&lt;li&gt;Consumer - crawl job urls&lt;/li&gt;
&lt;li&gt;Parser - parse data from job htmls&lt;/li&gt;
&lt;li&gt;Processor - process data and save it to file&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt; - connection sessions establish connection to server and keeps it open for more requests, this speeds up crawling and puts less stress on the host.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id="conclusion"&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Data is often the core of application functionality and web-crawling is a great tool to easily take advantage of public data available online.  &lt;/p&gt;
&lt;p&gt;Crawling is a diverse, multi-step process with a lot of viable approaches but to start off sticking with syncrhonious &lt;code&gt;requests&lt;/code&gt; and html parsers like &lt;code&gt;parsel&lt;/code&gt; can be more than enough for most projects.&lt;/p&gt;
&lt;p&gt;For further reading it's important to take a look at &lt;strong&gt;web caching&lt;/strong&gt; and &lt;strong&gt;rate limiting&lt;/strong&gt;, &lt;strong&gt;proxies&lt;/strong&gt; and &lt;strong&gt;failure and memory managing&lt;/strong&gt;. Finally there's a whole other problem of &lt;strong&gt;scaling&lt;/strong&gt; both crawling and data storage when it comes to millions of results. &lt;br/&gt;
I'll be covering these in later blogs &lt;/p&gt;</content><category term="code"></category><category term="scrapy"></category><category term="python"></category><category term="web-crawling"></category></entry><entry><title>How to fix redis busy</title><link href="https://granitosaurus.github.io/redis-busy.html" rel="alternate"></link><published>2018-08-28T00:00:00+02:00</published><updated>2018-08-28T00:00:00+02:00</updated><author><name>Bernardas Ališauskas</name></author><id>tag:granitosaurus.github.io,2018-08-28:/redis-busy.html</id><summary type="html">&lt;p&gt;How to fix annoying redis busy error when working with redis lua scripts and multiple clients&lt;/p&gt;</summary><content type="html">&lt;p&gt;Imagine scenario where you have a single redis server (which is single threaded) and you have multiple clients:&lt;/p&gt;
&lt;p&gt;&lt;img alt="redis structure" src="https://granitosaurus.github.io/images/redis-busy1.png"/&gt;&lt;/p&gt;
&lt;p&gt;Eventhough redis is single-threaded it has no problem handling this setup since it's blazing fast and knows how to manage it's task queue.&lt;br/&gt;
However if we ask redis server to perform a lua script evaluation it might take a while, which ends up with clients getting this nasty error:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;redis.exceptions.ResponseError: BUSY Redis is busy running a script. You can only call SCRIPT KILL or SHUTDOWN NOSAVE&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt="redis structure" src="https://granitosaurus.github.io/images/redis-busy2.png"/&gt;&lt;/p&gt;
&lt;h1 id="the fix"&gt;The Fix&lt;/h1&gt;
&lt;p&gt;Thi fix this we need to apply a fix to the client side - make it wait and retry this &lt;code&gt;ResponseError&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;To do this lets patch &lt;code&gt;Redis&lt;/code&gt; class in python's &lt;code&gt;redis-py&lt;/code&gt; client:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;redis&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Redis&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;MyRedis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Redis&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;lua_retry_time&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;120&lt;/span&gt;  &lt;span class="c1"&gt;# how many times to retry&lt;/span&gt;

    &lt;span class="c1"&gt;# override execute to retry busy errors &lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;execute_command&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;options&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lua_retry_time&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;execute_command&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;options&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;wait_time&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;wait_time&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lua_retry_time&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;execute_command&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;options&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;ResponseError&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="s1"&gt;'busy redis is busy'&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="s1"&gt;''&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lower&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
                    &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;wait_time&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="c1"&gt;# only print once&lt;/span&gt;
                    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Redis is busy, waiting up to 120 seconds...'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;wait_time&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;execute_command&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;options&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Since every command in this client goes through &lt;code&gt;execute_command&lt;/code&gt; method we can override it to keep retrying &lt;code&gt;Redis BUSY&lt;/code&gt; errors for a fixed amount of time.&lt;/p&gt;
&lt;p&gt;With this patch Redis client will retry the connection every 2 seconds if redis is busy evaluating LUA.&lt;/p&gt;
&lt;p&gt;&lt;img alt="redis final structure" src="https://granitosaurus.github.io/images/redis-busy3.png"/&gt;&lt;/p&gt;
&lt;h1 id="conclusion"&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;I've been trying to find some in-built solution for this and couldn't believe there's no official approach, neither with redis itself nor python's redis client. &lt;br/&gt;
The internet resources are very scarce around this issue too, so I figured I'd try and remedy this.&lt;/p&gt;</content><category term="code"></category><category term="linux"></category><category term="guide"></category><category term="redis"></category><category term="python"></category></entry><entry><title>Why I use GPL license</title><link href="https://granitosaurus.github.io/why-gpl.html" rel="alternate"></link><published>2017-11-18T00:00:00+01:00</published><updated>2017-11-18T00:00:00+01:00</updated><author><name>Bernardas Ališauskas</name></author><id>tag:granitosaurus.github.io,2017-11-18:/why-gpl.html</id><summary type="html">&lt;p&gt;Why I use GNU's General Public License and why I think it's a superior free or even open software license and anyone should consider it for your project.&lt;/p&gt;</summary><content type="html">&lt;p&gt;This issue has been discussed to death and I still find people blindly advocating MIT or even WTFPL licenses.
I'm far from a lawyer but I feel that there are few very generic and simple details about software licensing people
who lead open software projects should understand.&lt;/p&gt;
&lt;h2 id="protect yourself"&gt;Protect Yourself&lt;/h2&gt;
&lt;p&gt;First thing first - the license should protect the project contributors and creators. In legal terms it's called no-warranty-provided and exlucsion of it can be dangerous.&lt;br/&gt;
Technology law sucks -
it's outdated, overly complicated and widely regional where software itself has no borders.&lt;/p&gt;
&lt;p&gt;To illustrate tis danger imagine John made a library and used a license that does not fully protect the creators
from warranty responsibilities(like WTFPL). Now some company decides to use John's work in their software stack and
unfortunately John left a bug in his library that either exposed the company to theft or caused their technology to break. In this case the company could easily start lawsuit against John and argue that it was John's open source library that cause them to go under and John would be liable.&lt;/p&gt;
&lt;p&gt;Most linceses however have this included, GPL for example:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For the developers' and authors' protection, the GPL clearly explains
that there is no warranty for this free software.  For both users' and
authors' sake, the GPL requires that modified versions be marked as
changed, so that their problems will not be attributed erroneously to
authors of previous versions.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;While some occasional ones like WTFPL don't.&lt;/p&gt;
&lt;p&gt;To summarise, whatever license you use make sure to protect yourself - make sure you provide no warranty!&lt;/p&gt;
&lt;h2 id="philosophy and copyleft"&gt;Philosophy and Copyleft&lt;/h2&gt;
&lt;p&gt;It's important to consider license philosophy as well.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Copyleft is a general method for making a program (or other work) free
(in the sense of freedom, not &amp;ldquo;zero price&amp;rdquo;), and requiring all modified
and extended versions of the program to be free as well.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;For example GPL is a copyleft license. It's a "viral" license, 
which means any forks or modifications (that are published) have to also
carry the same license. This protects the projects ecosystem and enables 
a bunch of benefits for everyone involved.&lt;/p&gt;
&lt;h3 id="benefits"&gt;Benefits&lt;/h3&gt;
&lt;p&gt;On the other hand it's also worth considering the &lt;strong&gt;benefits&lt;/strong&gt; of viral copyleft nature of GPL type licenses:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Patches - since the license is viral any changes or forks will be public and those changes can be applied
to the original project very easily. This huge reason why Linux kernel itself is licensed under GPL.&lt;/li&gt;
&lt;li&gt;Freedom - it continues the message of free software. As project lead you have the
power to propagate the message as any derivatives will have to carry your choice.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="restrictions"&gt;Restrictions&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;it's too restrictive and puts too many gates in education!  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This quote comes up a lot when people argue against GPL, however this argument is false as &lt;strong&gt;GPL's restriction only applies to published software&lt;/strong&gt;&lt;br/&gt;
(&lt;a href="https://www.gnu.org/licenses/gpl-faq.html#GPLRequireSourcePostedPublic"&gt;as per FAQ&lt;/a&gt;).
So in other words you can modify and learn from software all you want and use it (even for profit)
as long as you don't publish it and try to turn it into a product of your own.&lt;/p&gt;
&lt;p&gt;Is it too restrictive for business? Maybe, but why would you be concerned about business?
The ecosystem should not expect anything from a business, it puts an unnecessary
centralization to an unreliable source. At the end of the day a business is out there with
one goal in mind - to make money - it's not a bad goal, but putting any expectations
for a business to go out of their way and support the ecosystem is wildly unreasonable.&lt;/p&gt;
&lt;h2 id="closing statement_1"&gt;Closing Statement&lt;/h2&gt;
&lt;p&gt;I'll continue using GPL license for all of my project where possible. It aligns with my ideology of software and
I believe I can develop and maintain software where I don't need to rely on adoption.&lt;/p&gt;
&lt;p&gt;Additional read:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.gnu.org/philosophy/pragmatic.html"&gt;Copyleft: Pragmactic Idealism&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://www.gnu.org/licenses/gpl-faq.html"&gt;GPL's FAQ&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://www.fsf.org/blogs/rms/selling-exceptions"&gt;It's possible to sell GPL exception&lt;/a&gt; &lt;/p&gt;</content><category term="code"></category><category term="floss"></category><category term="legal"></category></entry><entry><title>How to disable thinkpad trackpoint acceleration</title><link href="https://granitosaurus.github.io/disable-thinkpad-acceleration.html" rel="alternate"></link><published>2017-11-17T00:00:00+01:00</published><updated>2017-11-17T00:00:00+01:00</updated><author><name>Bernardas Ališauskas</name></author><id>tag:granitosaurus.github.io,2017-11-17:/disable-thinkpad-acceleration.html</id><summary type="html">&lt;p&gt;A short note on how to properly disable thinkpoint trackpad acceleration&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;I've got a new thinkpad laptop and I've been struggling with mouse acceleration on trackpoint,
turns out disabling it isn't as straight-forward as you'd expect&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;To get rid of this abomination of a feature that is enabled by default we need &lt;code&gt;xinput&lt;/code&gt;&lt;/p&gt;
&lt;h1 id="the fix"&gt;The Fix&lt;/h1&gt;
&lt;p&gt;First you need to find the code or name of your trackpoint:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ xinput list
⎡ Virtual core pointer                          &lt;span class="nv"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;    &lt;span class="o"&gt;[&lt;/span&gt;master pointer  &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="o"&gt;)]&lt;/span&gt;
⎜   ↳ Virtual core XTEST pointer                &lt;span class="nv"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;    &lt;span class="o"&gt;[&lt;/span&gt;slave  pointer  &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;)]&lt;/span&gt;
⎜   ↳ SynPS/2 Synaptics TouchPad                &lt;span class="nv"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;12&lt;/span&gt;   &lt;span class="o"&gt;[&lt;/span&gt;slave  pointer  &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;)]&lt;/span&gt;
⎜   ↳ TPPS/2 IBM TrackPoint                     &lt;span class="nv"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;13&lt;/span&gt;   &lt;span class="o"&gt;[&lt;/span&gt;slave  pointer  &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;)]&lt;/span&gt;
⎣ Virtual core keyboard                         &lt;span class="nv"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;    &lt;span class="o"&gt;[&lt;/span&gt;master keyboard &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;)]&lt;/span&gt;
    ↳ Virtual core XTEST keyboard               &lt;span class="nv"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;5&lt;/span&gt;    &lt;span class="o"&gt;[&lt;/span&gt;slave  keyboard &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="o"&gt;)]&lt;/span&gt;
    ↳ Power Button                              &lt;span class="nv"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;    &lt;span class="o"&gt;[&lt;/span&gt;slave  keyboard &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="o"&gt;)]&lt;/span&gt;
    ↳ Video Bus                                 &lt;span class="nv"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;    &lt;span class="o"&gt;[&lt;/span&gt;slave  keyboard &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="o"&gt;)]&lt;/span&gt;
    ↳ Sleep Button                              &lt;span class="nv"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;8&lt;/span&gt;    &lt;span class="o"&gt;[&lt;/span&gt;slave  keyboard &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="o"&gt;)]&lt;/span&gt;
    ↳ Integrated Camera: Integrated C           &lt;span class="nv"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;10&lt;/span&gt;   &lt;span class="o"&gt;[&lt;/span&gt;slave  keyboard &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="o"&gt;)]&lt;/span&gt;
    ↳ AT Translated Set &lt;span class="m"&gt;2&lt;/span&gt; keyboard              &lt;span class="nv"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;11&lt;/span&gt;   &lt;span class="o"&gt;[&lt;/span&gt;slave  keyboard &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="o"&gt;)]&lt;/span&gt;
    ↳ ThinkPad Extra Buttons                    &lt;span class="nv"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;14&lt;/span&gt;   &lt;span class="o"&gt;[&lt;/span&gt;slave  keyboard &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="o"&gt;)]&lt;/span&gt;
    ↳ SteelSeries  SteelSeries Arctis &lt;span class="m"&gt;7&lt;/span&gt;         &lt;span class="nv"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;9&lt;/span&gt;    &lt;span class="o"&gt;[&lt;/span&gt;slave  keyboard &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="o"&gt;)]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Our guy is &lt;code&gt;TPPS/2 IBM Trackpoint&lt;/code&gt; aka id &lt;code&gt;13&lt;/code&gt;.
Next we can see the properties of this prop:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ xinput list-props &lt;span class="m"&gt;13&lt;/span&gt;
Device &lt;span class="s1"&gt;'TPPS/2 IBM TrackPoint'&lt;/span&gt;:
        Device Enabled &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;140&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;:   &lt;span class="m"&gt;1&lt;/span&gt;
        Coordinate Transformation Matrix &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;142&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;: &lt;span class="m"&gt;1&lt;/span&gt;.000000, &lt;span class="m"&gt;0&lt;/span&gt;.000000, &lt;span class="m"&gt;0&lt;/span&gt;.000000, &lt;span class="m"&gt;0&lt;/span&gt;.000000, &lt;span class="m"&gt;1&lt;/span&gt;.000000, &lt;span class="m"&gt;0&lt;/span&gt;.000000, &lt;span class="m"&gt;0&lt;/span&gt;.000000, &lt;span class="m"&gt;0&lt;/span&gt;.000000, &lt;span class="m"&gt;1&lt;/span&gt;.000000
        libinput Natural Scrolling Enabled &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;310&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;:       &lt;span class="m"&gt;0&lt;/span&gt;
        libinput Natural Scrolling Enabled Default &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;311&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;:       &lt;span class="m"&gt;0&lt;/span&gt;
        libinput Left Handed Enabled &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;312&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;:     &lt;span class="m"&gt;0&lt;/span&gt;
        libinput Left Handed Enabled Default &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;313&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;:     &lt;span class="m"&gt;0&lt;/span&gt;
        libinput Accel Speed &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;314&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;:     &lt;span class="m"&gt;0&lt;/span&gt;
        libinput Accel Speed Default &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;315&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;:     &lt;span class="m"&gt;0&lt;/span&gt;.000000
        libinput Accel Profiles Available &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;316&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;:        &lt;span class="m"&gt;1&lt;/span&gt;, &lt;span class="m"&gt;1&lt;/span&gt;
        libinput Accel Profile Enabled &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;317&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;:   &lt;span class="m"&gt;1&lt;/span&gt;, &lt;span class="m"&gt;0&lt;/span&gt;
        libinput Accel Profile Enabled Default &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;318&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;:   &lt;span class="m"&gt;1&lt;/span&gt;, &lt;span class="m"&gt;0&lt;/span&gt;
        libinput Scroll Methods Available &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;319&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;:        &lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="m"&gt;1&lt;/span&gt;
        libinput Scroll Method Enabled &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;320&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;:   &lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="m"&gt;1&lt;/span&gt;
        libinput Scroll Method Enabled Default &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;321&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;:   &lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="m"&gt;1&lt;/span&gt;
        libinput Button Scrolling Button &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;322&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;: &lt;span class="m"&gt;2&lt;/span&gt;
        libinput Button Scrolling Button Default &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;323&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;: &lt;span class="m"&gt;2&lt;/span&gt;
        libinput Middle Emulation Enabled &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;324&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;:        &lt;span class="m"&gt;0&lt;/span&gt;
        libinput Middle Emulation Enabled Default &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;325&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;:        &lt;span class="m"&gt;0&lt;/span&gt;
        libinput Send Events Modes Available &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;260&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;:     &lt;span class="m"&gt;1&lt;/span&gt;, &lt;span class="m"&gt;0&lt;/span&gt;
        libinput Send Events Mode Enabled &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;261&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;:        &lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="m"&gt;0&lt;/span&gt;
        libinput Send Events Mode Enabled Default &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;262&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;:        &lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="m"&gt;0&lt;/span&gt;
        Device Node &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;263&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;:      &lt;span class="s2"&gt;"/dev/input/event18"&lt;/span&gt;
        Device Product ID &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;264&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;:        &lt;span class="m"&gt;2&lt;/span&gt;, &lt;span class="m"&gt;10&lt;/span&gt;
        libinput Drag Lock Buttons &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;326&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;:       &amp;lt;no items&amp;gt;
        libinput Horizontal Scroll Enabled &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;327&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;:       &lt;span class="m"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To disable acceleration we are interested in one of these two settings:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;        libinput Accel Speed (314):     0&lt;/span&gt;
&lt;span class="err"&gt;        libinput Accel Profile Enabled (317):   1, 0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We can either diminish/change the acceleration speed by:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;# to disable we can use negative acceleration&lt;/span&gt;
&lt;span class="err"&gt;$ xinput set-prop 13 314 -1&lt;/span&gt;
&lt;span class="err"&gt;# or we can disable acceleration profile entirely&lt;/span&gt;
&lt;span class="err"&gt;$ xinput set-prop 13 317 0 1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note, don't use both, -1 with disabled acceleration pretty much disables the devices.&lt;/p&gt;
&lt;h1 id="make it persisntant"&gt;Make It Persisntant&lt;/h1&gt;
&lt;p&gt;To make the change persist after restart simply add the config line it to your &lt;code&gt;~/.xsessionrc&lt;/code&gt; file, e.g.:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;echo "xinput set-prop 13 317 0 1" &amp;gt;&amp;gt; ~/.xsessionrc&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="code"></category><category term="linux"></category><category term="guide"></category></entry><entry><title>Securing Data With eCryptfs</title><link href="https://granitosaurus.github.io/ecrypt-yourself.html" rel="alternate"></link><published>2017-10-22T00:00:00+02:00</published><updated>2017-10-22T00:00:00+02:00</updated><author><name>Bernardas Ališauskas</name></author><id>tag:granitosaurus.github.io,2017-10-22:/ecrypt-yourself.html</id><summary type="html">&lt;p&gt;protect your sensitive data like crypto wallets with eCrypt overlay filesystem!&lt;/p&gt;</summary><content type="html">&lt;p&gt;Since I started dabbling in Cryptocurrency I've been feeling a bit paranoid about protecting my wallet information and keys. Fortunately there are already tools that are dead easy to use. &lt;br/&gt;
The standard tool for linux is called eCryptfs and let me tell you how awesome and convenient it is!&lt;/p&gt;
&lt;h1 id="ecryptfs"&gt;eCryptfs&lt;/h1&gt;
&lt;p&gt;eCryptfs is a cryptographic overlay filesystem for Linux. It's a great tool to encrypt some private data like cryptocurrency wallet keys, private pictures &amp;mdash; anything really.&lt;br/&gt;
It allows you to mount a password protected, encrypted filesystem on your usual unencrypted filesystem:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;dex&lt;/span&gt;&lt;span class="err"&gt;@&lt;/span&gt;&lt;span class="o"&gt;~/&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;private&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ls&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;Access&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Your&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Private&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="k"&gt;Data&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;desktop&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;README&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;txt&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ecryptfs&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;mount&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;private&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;Enter&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;your&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;login&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;passphrase&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;Inserted&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;auth&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;tok&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;with&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sig&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;xxxxxx&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;into&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;user&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;session&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;keyring&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nl"&gt;INFO&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Your&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;private&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;directory&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;has&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;been&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;mounted&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nl"&gt;INFO&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;To&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;see&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;this&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;change&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ow"&gt;in&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;your&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;current&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;shell&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="n"&gt;cd&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;home&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dex&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;private&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;dex&lt;/span&gt;&lt;span class="err"&gt;@&lt;/span&gt;&lt;span class="o"&gt;~/&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;private&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;cd&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;dex&lt;/span&gt;&lt;span class="err"&gt;@&lt;/span&gt;&lt;span class="o"&gt;~/&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;private&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ls&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="n"&gt;myetherwallet&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;btc&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Pretty damn cool - simple and secure!  &lt;/p&gt;
&lt;h2 id="setup"&gt;Setup&lt;/h2&gt;
&lt;p&gt;eCryptfs setup is dead easy!&lt;br/&gt;
Since linux version 3.18 eCrypt overlay filesystem is included with core kernel. 
Simply enable it with:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;modprobe ecryptfs&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then we need some tools to easily mount, unmount and generate our filesystem: &lt;code&gt;ecryptfs-utils&lt;/code&gt; has everything we would need and is available on every linux package manager:  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;sudo apt install ecryptfs-utils  # Ubuntu&lt;/span&gt;
&lt;span class="err"&gt;sudo pacman -S ecryptfs-utils  # Arch&lt;/span&gt;
&lt;span class="err"&gt;etc. etc.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Once you have it installed you'll find your user-space path populated with a bunch of ecryptfs utils, just type in your terminal &lt;code&gt;ecryptfs-&lt;/code&gt; and press tab to see the goodies:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;[dex@nanosaurus ~]$ ecryptfs-&amp;lt;tab&amp;gt;&lt;/span&gt;
&lt;span class="err"&gt;ecryptfs-add-passphrase&lt;/span&gt;
&lt;span class="err"&gt;ecryptfs-find&lt;/span&gt;
&lt;span class="err"&gt;ecryptfs-insert-wrapped-passphrase-into-keyring&lt;/span&gt;
&lt;span class="err"&gt;ecryptfs-manager&lt;/span&gt;
&lt;span class="err"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally to initiate an ecryptfs system we need to run:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ ecryptfs-setup-private --nopwcheck --noautomount
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We use &lt;code&gt;--nopwcheck&lt;/code&gt; and &lt;code&gt;--noautomount&lt;/code&gt; flags here for extra security.   &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;nopwcheck&lt;/code&gt; allows us to use different password from our user's password   &lt;/li&gt;
&lt;li&gt;&lt;code&gt;noautomount&lt;/code&gt; disables automatic encrypted system mounting, since it's also not a very great idea and wouldn't work if our encryption password is different from our user's one.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This command will ask you for &lt;code&gt;login&lt;/code&gt; and &lt;code&gt;mount&lt;/code&gt; passwords. For login password use your own password and for mount password leave it empty as ecryptfs will create it for you using your login password as a seed.&lt;/p&gt;
&lt;p&gt;Afterwards the system will be initiated and  &lt;code&gt;~/Private&lt;/code&gt; and &lt;code&gt;~/.ecryptfs&lt;/code&gt; directories will be created.  &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note: you want to backup your encrypted mount password which is located in &lt;code&gt;~/.ecryptfs/wrapped-passphrase&lt;/code&gt;. Remember that mount password is generated from your login password, so the passphrase is completely useless without your login password - put a copy of this file somewhere where you will never lose it!&lt;/em&gt;&lt;/p&gt;
&lt;h2 id="usage"&gt;Usage&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;~/Private&lt;/code&gt; is your ecryptfs encrypted directory from now on. To use it you must mount it with &lt;code&gt;ecryptfs-mount-private&lt;/code&gt; command and once you're done using it use &lt;code&gt;ecryptfs-umount-private&lt;/code&gt; command to make it inaccessible once again:  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;dex@~/Private $ ls&lt;/span&gt;
&lt;span class="err"&gt;Access-Your-Private-Data.desktop  README.txt&lt;/span&gt;
&lt;span class="err"&gt;$ ecryptfs-mount-private &lt;/span&gt;
&lt;span class="err"&gt;dex@~/Private $ cd .&lt;/span&gt;
&lt;span class="err"&gt;dex@~/Private $ ls &lt;/span&gt;
&lt;span class="err"&gt;myetherwallet  btc diary emberassing_hobbies&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;That's it! Now you have a safe directory on your computer where you can store sensitive data! Even if someone gets access to your user's homespace they'll still need your ecryptfs password to get anything out of it.  &lt;/p&gt;
&lt;h2 id="customizing"&gt;Customizing&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;~/Private&lt;/code&gt; is a pretty terrible name. It's Camelcase and I'd very much prefer it to be hidden.&lt;br/&gt;
We can change it to &lt;code&gt;~/.private&lt;/code&gt; very easily though:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;mv ~/Private ~/.private&lt;/span&gt;
&lt;span class="err"&gt;echo /home/dex/.private &amp;gt; ~/.ecryptfs/Private.mnt&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h1 id="general security tips_1"&gt;General Security tips&lt;/h1&gt;
&lt;h2 id="the three rule"&gt;The Three Rule&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;If it doesn't exist in &lt;strong&gt;three&lt;/strong&gt; places it doesn't exist at all.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Fortunately ecryptfs directory acts like a normal directory so you can easily back it up to usb-stick, cloud storage or even email. Really just put that shit everywhere as longs as you have your login and mount passwords safe no one will be able to access your stuff.&lt;/p&gt;
&lt;p&gt;We've all heard magical stories about people losing usb sticks with their bitcoin wallets. Well if you had your wallet encrypted and in three different places that would have never happened!&lt;/p&gt;
&lt;h2 id="long passwords triumph"&gt;Long Passwords Triumph&lt;/h2&gt;
&lt;p&gt;I don't think I can top the explanation by this &lt;a href="https://xkcd.com/936/"&gt;xkcd comic&lt;/a&gt; so I'll just leave you with it and say that just have a simple a-z password which is at least 13 characters long.  &lt;/p&gt;
&lt;h1 id="further reading_1"&gt;Further Reading&lt;/h1&gt;
&lt;p&gt;If you want to dig deeper I suggest arch-wiki &lt;a href="https://wiki.archlinux.org/index.php/ECryptfs"&gt;article&lt;/a&gt; or symply &lt;code&gt;man ecryptfs&lt;/code&gt;!
Additionally &lt;a href="https://stackoverflow.com/questions/tagged/ecryptfs?sort=votes&amp;amp;pageSize=15"&gt;top questions on stackoverflow&lt;/a&gt; also offer some interesting read.&lt;/p&gt;</content><category term="code"></category><category term="linux"></category><category term="guide"></category><category term="crypto"></category><category term="security"></category></entry><entry><title>wisdom.cat</title><link href="https://granitosaurus.github.io/wisdom-cat.html" rel="alternate"></link><published>2017-04-01T00:00:00+02:00</published><updated>2017-04-01T00:00:00+02:00</updated><author><name>Bernardas Ališauskas</name></author><id>tag:granitosaurus.github.io,2017-04-01:/wisdom-cat.html</id><summary type="html">&lt;p&gt;Recently I made small website in flask for aggregating educational youtube videos and I'd like to share my experience.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've always wanted to make a webapp and flask always looked appealing but deployment and production hassle really turned me off. A week ago I tried to force myself through it and I have to say, it's really not that bad!&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This is not a guide and you most likely won't learn anything - it's more of a condense story of how wisdom.cat was developed and doesn't really serve any other purpose&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="wisdom.cat" src="https://i.imgur.com/JppvDUZ.png"/&gt;&lt;/p&gt;
&lt;h2 id="wisdom.cat"&gt;Wisdom.cat&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;$ cat wisdom&lt;br/&gt;
=( ^ &amp;gt;w&amp;lt; ^ )= &lt;br/&gt;
wisdom.cat - is a video aggregator website that aggregates bite size videos &lt;br/&gt;
which are in some way educational. The intention of this website is&lt;br/&gt;
to have something beneficial to watch during short down-time periods; &lt;br/&gt;
https://github.com/Granitosaurus/wisdom.cat  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I work remotely and I tend to eat at home so I usually watch a video or two during my lunch break. However I wanted to make sure I don't completely waste this time and don't let my brain fall a sleep or lose track so I've been watching education videos to compensate.&lt;br/&gt;
So the goal of &lt;a href="http://wisdom.cat"&gt;wisdom.cat&lt;/a&gt; is to solve this issue and provide me and others who are stuck in a similar position something to watch.  &lt;/p&gt;
&lt;h3 id="alternatives and inspirations"&gt;Alternatives and Inspirations&lt;/h3&gt;
&lt;p&gt;&lt;img alt="looking around" src="https://i.redd.it/1h2rkgvxzv6y.gif"/&gt; &lt;/p&gt;
&lt;p&gt;For quite a while a brilliant website (that wisdom.cat is more or less a clone of) performed this function - it's called http://unplugthetv.com. However as time went on the feed slowed down to the point where it has been completely dead since October of 2016.&lt;br/&gt;
I didn't like few things on that website; first that the feed was fairly slow and the second, much more important one, that there was no way to customize it. So a lot of unwanted things ended up in the feed, my personal example being the  TED channel, it used to be brilliant - 4 years ago, now it's utter garbage that if anything makes people more dumb instead of educating them.&lt;/p&gt;
&lt;p&gt;So in hindsight you could say wisdom cat was born from a dead cool website and my hatred for TED (TED-ED is really lovely though!).&lt;/p&gt;
&lt;p&gt;Some alternatives I came across while doing my research that are worth mentioning:&lt;br/&gt;
http://reddit.com/r/mealtimevideos - similar purpose, however it's not focused on education.&lt;br/&gt;
Curiousity app - I've never used it but heard one person on irc.#flask say that wisdom.cat is similar.  &lt;/p&gt;
&lt;h2 id="databases_1"&gt;Databases&lt;/h2&gt;
&lt;p&gt;&lt;img alt="wisdomcat database story" src="https://granitosaurus.github.io/images/wisdomcat-db.png"/&gt; &lt;/p&gt;
&lt;p&gt;I didn't know much about designing webapp data storage at the time and just went with sqlite3, which didn't play well with pythonanywhere hosting that I was trying to use at the time. So I made a switch to mysql, which was a miserable  mistake. Mysql is dreadful to work with and I've spent more time working on the database and such than on the web app itself. &lt;br/&gt;
Frankly it was extremely unenjoyable experience and since this project was my spare time thing I came to a brilliant conclusion to try something different.   &lt;/p&gt;
&lt;p&gt;I got Redis! And honestly, it's been a complete pleasure starting the very moment I ran &lt;code&gt;pacman -S redis&lt;/code&gt;.&lt;br/&gt;
So what's so great about it? Well it might sound clich&amp;egrave; but It Just Works&amp;trade;, no really after I installed it via pacman, started the daemon via systemctl and got a python api (python-redis or flask-redis) I had to add pretty much 2 lines to my youtube scraper to store the data and 4 lines to my flask views to display it - it was liberating!  &lt;/p&gt;
&lt;p&gt;One important thing I learned when it comes to Redis is to "store data the same way you will query it". Since redis doesn't really have a full query mechanism behind it, you might end up stuck without being able to get your data without a bunch of python code to help you out.&lt;br/&gt;
My first attempt was to write every video to &lt;code&gt;video_&amp;lt;id&amp;gt;&lt;/code&gt; but since I wanted wisdom.cat to have filters for channels that didn't end up being as efficient. Nowhere near of being a huge performance hit but in short time it might become noticeable.&lt;br/&gt;
Then I just wrote video data to Redis lists named after channels, i.e. "channel_CGP Grey" will contain a list of videos, that can be updated and modified - which solved this non-issue completely!  &lt;/p&gt;
&lt;h2 id="flask"&gt;Flask&lt;/h2&gt;
&lt;p&gt;Flask was an easy choice for wisdom.cat; it was popular(read a lot of learning resources), light-weight and in python!&lt;br/&gt;
I'm not sure if I have much to add other than few struggles I had as a newb.&lt;br/&gt;
The circular imports got me a time or two, because for some reason I decided to keep &lt;code&gt;app&lt;/code&gt; object in &lt;code&gt;__init__.py&lt;/code&gt; and ended up kinda liking it.  &lt;/p&gt;
&lt;p&gt;The biggest issue I had was the sessions. Initially wisdom cat would generate video queue and channel subscriptions and put them to flask session, aka secure cookie. Now this brought an impossible to debug issue that made be dippy few times. Turns out the cookie/session ended up being so big it would not update anymore appropriately since cookie has 4k byte limit and the wisdom cat setup, at the time with 30 videos, was already reaching that!&lt;br/&gt;
So needless to say it was a bad idea from the very get go, fortunately with redis up and running it was no longer an issue that would be difficult to solve.&lt;/p&gt;
&lt;p&gt;All in all it's hard to say something original about Flask since it has such a huge community and so many opinions, research and information already that anything I'd say would be awfully redundant so I'll just say that Flask was a real pleasure to work with and honestly, I can't wait to start a new project already!  &lt;/p&gt;
&lt;h2 id="deploying"&gt;Deploying&lt;/h2&gt;
&lt;p&gt;This was my most dreaded bit. I've been playing with servers to run crawlers and some notification tools for some time but I've never exposed them to public or made them accessible.&lt;br/&gt;
Fortunately it all sounds more complicated than it actually is. All you need is an application, &lt;a href="https://en.wikipedia.org/wiki/Web_Server_Gateway_Interface"&gt;wsgi&lt;/a&gt; tool, some daemons and an afternoon!  &lt;/p&gt;
&lt;p&gt;I ended up renting a &lt;a href="https://www.linode.com/?r=37112fcbb52a0f3c556a91b37d215d72e4ef5702"&gt;linode&lt;/a&gt; (which is really lovely!) and using arch node with systemd, nginx and gunicorn. &lt;br/&gt;
I've been using arch and systemd for few years now so this part was a breeze, however nginx gave me a bit of trouble. Mostly because most of the tutorials, guides and documentation assumed that it's running on Ubuntu which for some reason uses unusual structure and stores servers in &lt;code&gt;sites-enabled&lt;/code&gt; and &lt;code&gt;sites-available&lt;/code&gt; which were not present in arch(or most of the other distros). Apparently this was to replicated some apache server structure so I decided to join the cool kid's club and replicate the same structure with &lt;code&gt;inludes&lt;/code&gt; and system links - it worked out perfectly fine and I with few lines of configs it was working.&lt;/p&gt;
&lt;p&gt;Finally I wrote up two daemon services: &lt;code&gt;gunicorn&lt;/code&gt; wsgi service to launch and expose the app, and a timer service - to run video crawler every half an hour, to update the video feed.&lt;/p&gt;
&lt;p&gt;And with that wisdom.cat was finally drawing it's first breaths! &lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;This was a really fun little project and I highly recommend investing some time into learning how to make a simple web app like this - it opens up so many gates for so many opportunities!&lt;/p&gt;</content><category term="code"></category><category term="python"></category><category term="linux"></category><category term="flask"></category><category term="webdev"></category></entry><entry><title>Getting Terminal Size In Python</title><link href="https://granitosaurus.github.io/getting-terminal-size.html" rel="alternate"></link><published>2017-01-26T00:00:00+01:00</published><updated>2017-01-26T00:00:00+01:00</updated><author><name>Bernardas Ališauskas</name></author><id>tag:granitosaurus.github.io,2017-01-26:/getting-terminal-size.html</id><summary type="html">&lt;p&gt;Getting terminal size can be vital for your application, especially if you are doing some serious printing or drawing. There are some few tricks worth noting that I'd like to share.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Getting terminal size can be vital for your application, especially if you are doing some serious printing or drawing. However there are some few tricks worth noting that I'd like to share in this blog post.&lt;/p&gt;
&lt;p&gt;First of all the recommended way or the "pythonic" way of retrieving terminal size for python3 is:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/usr/bin/env python3&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;shutil&lt;/span&gt;
&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rows&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;shutil&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_terminal_size&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fallback&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;80&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And it works pretty great, well for the most part that is.  &lt;/p&gt;
&lt;h2 id="the issue"&gt;The Issue&lt;/h2&gt;
&lt;p&gt;This particular function is just a high level wrapper around low level cpython function &lt;code&gt;os.get_terminal_size&lt;/code&gt; and the only real thing it does is handle an exception and returns &lt;code&gt;fallback&lt;/code&gt; values if that's the case.&lt;/p&gt;
&lt;p&gt;However there's a huge pitfall with this function and it's that &lt;strong&gt;it doesn't work with terminal pipes!&lt;/strong&gt; &lt;br/&gt;
To confirm and test that with we can try this simple script &lt;code&gt;size.py&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;shutil&lt;/span&gt;

&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rows&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;shutil&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_terminal_size&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fallback&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;123&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;456&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdout&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'cols:&lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;rows:&lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rows&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ python size.py
cols:89
rows:22
$ python size.py &lt;span class="p"&gt;|&lt;/span&gt; cat
cols:123
rows:456
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;89 to 22 is my actual size however when piping to anything, including python itself, the size seems to fallback to the fallback values, which in most cases defeats the whole purpose of retrieving the terminal size.&lt;/p&gt;
&lt;h3 id="making it work!"&gt;Making It Work!&lt;/h3&gt;
&lt;p&gt;The solution is pretty simple - use the other function instead!&lt;br/&gt;
If we use &lt;code&gt;os.get_terminal_size(0)&lt;/code&gt; function, we'll get it working with piping too!&lt;/p&gt;
&lt;p&gt;To test that lets change our script:  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/usr/bin/env python3&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;

&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rows&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_terminal_size&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdout&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'cols:&lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;rows:&lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rows&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The thing to note here is the positional argument &lt;code&gt;0&lt;/code&gt; in &lt;code&gt;os.get_terminal_size()&lt;/code&gt; function, which tells which &lt;a href="https://en.wikipedia.org/wiki/File_descriptor"&gt;file descriptor&lt;/a&gt; to use: &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;0 - Standard Input&lt;br/&gt;
1 - Standard Output&lt;br/&gt;
2 - Standard Error  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;By default both &lt;code&gt;os&lt;/code&gt; and &lt;code&gt;shutil&lt;/code&gt; functions use &lt;code&gt;1&lt;/code&gt;, which stands for Standard Output. This means that if we pipe and this output detaches itself we get an OsError:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ne"&gt;OSError&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;Errno&lt;/span&gt; &lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;Inappropriate&lt;/span&gt; &lt;span class="n"&gt;ioctl&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;device&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This default somewhat makes sense if the size of your terminal changes when the output is displayed, but I'm having trouble even imagining an example where that would be the case.&lt;/p&gt;
&lt;p&gt;So if we were to run our script now, we'd get the results we are looking for:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ python size.py
cols:89
rows:22
$ python size.py &lt;span class="p"&gt;|&lt;/span&gt; cat
cols:89
rows:22
&lt;span class="c1"&gt;# Even if we pipe multiple times!&lt;/span&gt;
$ python size.py &lt;span class="p"&gt;|&lt;/span&gt; grep . &lt;span class="p"&gt;|&lt;/span&gt; cat
cols:89
rows:22
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="edit_1"&gt;Edit&lt;/h2&gt;
&lt;p&gt;As user bearded_unix_guy pointed out on &lt;a href="https://www.reddit.com/r/Python/comments/5q7b36/getting_terminal_size_in_python/dcxil66/"&gt;reddit&lt;/a&gt;, using stdin(argument 0) might not always work, in particular it wont work when we pipe to our app: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;cat&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In case like above we actually want to use stdout(default argument) since it's not detached. However what about if your app is in the middle: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;cat&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;cat&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In this case neither stdout nor stdin will work, but sterr(2) will!&lt;br/&gt;
So to combine all of these to cover all of the cases we can simply wrap it in a for loop with exception catching:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_terminal_size&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fallback&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;80&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rows&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_terminal_size&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;OSError&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;continue&lt;/span&gt;
        &lt;span class="k"&gt;break&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="c1"&gt;# set default if the loop completes which means all failed&lt;/span&gt;
        &lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rows&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fallback&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rows&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And there you go, you can use that instead of &lt;code&gt;os.get_terminal_size()&lt;/code&gt; and have a pipe-foolproof terminal size getter! &lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;I've spent more time than I'd like to admit trying to figure this out and the &lt;a href="http://stackoverflow.com/a/41864359/3737009"&gt;stackoverflow thread&lt;/a&gt; for this subject only left me more confused.&lt;br/&gt;
As always if you have any questions, critique or notices feel free to leave a comment!&lt;/p&gt;</content><category term="code"></category><category term="python"></category><category term="linux"></category><category term="guide"></category></entry><entry><title>My Bin: center</title><link href="https://granitosaurus.github.io/my-bin-center.html" rel="alternate"></link><published>2017-01-18T00:00:00+01:00</published><updated>2017-01-18T00:00:00+01:00</updated><author><name>Bernardas Ališauskas</name></author><id>tag:granitosaurus.github.io,2017-01-18:/my-bin-center.html</id><summary type="html">&lt;p&gt;"My bin" is series of blog post where I cover some useful or at least interesting programs, scripts or hacks that I have in my ~/bin. In this one I cover a small pipeable app that simply centers text to your terminal size.&lt;/p&gt;</summary><content type="html">&lt;p&gt;People are naturally lazy and strive to automate as much as possible. I'm no exception and my user scripts directory &lt;code&gt;~/bin&lt;/code&gt; is full of scripts that make my life easier or at least makes me feel that is. &lt;br/&gt;
On how to setup your environment for easily accessible scripting see my &lt;a href="/python-scripts.html"&gt;Guide: setup for python scripting&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;Today I want to show you and explain some bits of a little python script for centering text. It's isn't particularly special, but it's a great base to show off how awesome and powerful python command line tools can be!&lt;br/&gt;
It's a simple pipeable script that takes in some text, centers it according to your terminal size and outputs it to standard output.My use case for this is for reading poems and by default they are not centered properly. To add to that I also like to constantly resize my terminal window because I'm running &lt;a href="http://i3wm.org/"&gt;i3wm&lt;/a&gt; - a tilling windows manager for linux, which forces every window to use up all of the space it can, which makes them very much dynamic and unpredictable.&lt;/p&gt;
&lt;p&gt;In other words it turns something like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ cat raven.md
Once upon a midnight dreary, &lt;span class="k"&gt;while&lt;/span&gt; I pondered, weak and weary,
Over many a quaint and curious volume of forgotten lore,
While I nodded, nearly napping, suddenly there came a tapping,
As of some one gently rapping, rapping at my chamber door.
&lt;span class="s1"&gt;'Tis some visitor,'&lt;/span&gt; I muttered, &lt;span class="s1"&gt;'tapping at my chamber door-&lt;/span&gt;
&lt;span class="s1"&gt;Only this, and nothing more.'&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Into:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ cat raven.md &lt;span class="p"&gt;|&lt;/span&gt; center
             Once upon a midnight dreary, &lt;span class="k"&gt;while&lt;/span&gt; I pondered, weak and weary,              
                Over many a quaint and curious volume of forgotten lore,                 
             While I nodded, nearly napping, suddenly there came a tapping,              
               As of some one gently rapping, rapping at my chamber door.                
              &lt;span class="s1"&gt;'Tis some visitor,'&lt;/span&gt; I muttered, &lt;span class="s1"&gt;'tapping at my chamber door-               &lt;/span&gt;
&lt;span class="s1"&gt;                              Only this, and nothing more.'&lt;/span&gt;   
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;While taking your current terminal size into account, so no matter what you're doing or where you are the text will nice and pretty.   &lt;/p&gt;
&lt;h3 id="source"&gt;Source&lt;/h3&gt;
&lt;p&gt;Now lets take a look at the source code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="c1"&gt;#!/usr/bin/env python3&lt;/span&gt;
    &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;click&lt;/span&gt;
    &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
    &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;


    &lt;span class="nd"&gt;@click&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;command&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="nd"&gt;@click&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'input'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;required&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;click&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;File&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'r'&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="nd"&gt;@click&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'output'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;required&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;click&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;File&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'w'&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="nd"&gt;@click&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;option&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'-l'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'--length'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;help&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'maximum line length [default:current terminal size]'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;click&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;INT&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;cli&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;length&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;"""Simple, pipeable tool for centering text"""&lt;/span&gt;
        &lt;span class="n"&gt;columns&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_terminal_size&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;  &lt;span class="c1"&gt;#1&lt;/span&gt;
        &lt;span class="n"&gt;source&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;readlines&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;input&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdin&lt;/span&gt;  &lt;span class="c1"&gt;#2&lt;/span&gt;
        &lt;span class="n"&gt;_format&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'{{:^&lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;}}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;length&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  &lt;span class="c1"&gt;#3&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;source&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="c1"&gt;#4&lt;/span&gt;
            &lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;_format&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdout&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;"__main__"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;cli&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="explanation"&gt;Explanation&lt;/h3&gt;
&lt;p&gt;I love &lt;code&gt;click&lt;/code&gt; library, which is a tool for creating command line interfaces. It's beautiful, easy and saves so much space and time. So we start off with two positional arguments for input and output filenames, these are not necessary for the pipe logic we need but is a nice addition if there's a need for standalone function and only takes two extra lines, so why not!  &lt;br/&gt;
Next we have custom option for length which allows overriding maximum line length. In case you have a very huge terminal window and you just want a nice margin instead of the text being at the very center of your screen.
Finally there's the program itself:&lt;br/&gt;
&lt;code&gt;#1&lt;/code&gt; - We retrieve dimensions of the current terminal window. This returns a tuple of &lt;code&gt;(columns, rows)&lt;/code&gt; since we only care about columns we take the first member. &lt;br/&gt;
Check out a related blog entry why we are using this function instead of alternatives &lt;a href="/getting-terminal-size.html"&gt;here&lt;/a&gt;&lt;br/&gt;
&lt;code&gt;#2&lt;/code&gt; - We decide on which source to use for input, if first position argument is supplied to script, we'll use that as a source, otherwise use standard input.&lt;br/&gt;
&lt;code&gt;#3&lt;/code&gt; - This might appear complicated but what we are doing here is creating a format that we will use to format every line of our text. The line evaluates to &lt;code&gt;{:^&amp;lt;terminal_size&amp;gt;}\n&lt;/code&gt; now if we call &lt;code&gt;.format()&lt;/code&gt; on that we can insert text and it will be centered. For more check out &lt;a href="https://docs.python.org/3.1/library/string.html#string-formatting"&gt;python's string formatting&lt;/a&gt;, it's awesome!&lt;br/&gt;
&lt;code&gt;#4&lt;/code&gt; - And lastly we have the loop itself. Here we loop through every line, center it and either write it to file if the second positional argument is supplied or put it straight to standard output.  &lt;/p&gt;
&lt;h3 id="improvements"&gt;Improvements&lt;/h3&gt;
&lt;p&gt;You could probably go wild with a bunch of flags and modifications but it's important to remember to KISS - keep it simple stupid. With pipes, aliases and various other shortcuts leaving this script to do one job is very much a good idea! :) &lt;/p&gt;
&lt;h3 id="conclusion"&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;I'd like to encourage anyone who uses ugly awk scripts and aliases just write a short command line application with python and &lt;code&gt;click&lt;/code&gt;. It takes no longer than 10 minutes, it's beautiful, usable, readable and easily shareable!&lt;br/&gt;
Let me know if you have any questions and stay tuned for more scripts and explanations!&lt;/p&gt;</content><category term="code"></category><category term="python"></category><category term="linux"></category><category term="guide"></category><category term="my-bin"></category></entry><entry><title>Guide: setup for python scripting</title><link href="https://granitosaurus.github.io/python-scripts.html" rel="alternate"></link><published>2017-01-17T00:00:00+01:00</published><updated>2017-01-17T00:00:00+01:00</updated><author><name>Bernardas Ališauskas</name></author><id>tag:granitosaurus.github.io,2017-01-17:/python-scripts.html</id><summary type="html">&lt;p&gt;Short guide on how to setup an environment for executable python scripts&lt;/p&gt;</summary><content type="html">&lt;p&gt;Few python scripts can make your daily routines significantly easier and enjoyable. In this post I'll cover how to set up your linux environment to have your scripts always easily accessible.&lt;br/&gt;
In other words, how to make this reality:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ amicool 
Yes you are, keep it up!
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To start off we need to create a directory where your scripts be located. A de facto standard is &lt;code&gt;~/bin&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ mkdir bin
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="handling the path"&gt;Handling the PATH&lt;/h2&gt;
&lt;p&gt;Now depending on your system and the shell you use, this directory might already be created or might not be in your &lt;code&gt;PATH&lt;/code&gt; environment at all.&lt;br/&gt;
&lt;code&gt;PATH&lt;/code&gt; environment variable is a list of locations your shell will look for executable files - programs in other words. So if you're using good ol' bash simply adding this line to your &lt;code&gt;~/.bashrc&lt;/code&gt; file will do:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;export PATH="~/bin:$PATH"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="creating the script"&gt;Creating the script&lt;/h2&gt;
&lt;p&gt;Now we can create the script itself:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ touch ~/bin/amicool 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Notice that we do not use &lt;code&gt;.py&lt;/code&gt; extension, because linux takes executables in PATH literally and we don't want to type the extension whenever we call the script.&lt;br/&gt;
We should populate this script with some actual code:&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;1
2
3
4&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/usr/bin/env python3&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;'__main__'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Yes you are, keep it up!"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;p&gt;Notice that we start of the file with &lt;code&gt;#!/usr/bin/env python3&lt;/code&gt;. This is called shebang, it's basically a header that tells your operating system what to use to execute the file, in this case we want to use &lt;code&gt;python3&lt;/code&gt;.&lt;br/&gt;
Afterwards we have the most simple of python code that just prints some text when call it directly, you see when you call a python module directly the magic variable &lt;code&gt;__name__&lt;/code&gt; is being set to &lt;code&gt;'__main__'&lt;/code&gt; so you can gate some code in your script behind it so it would only be executed if it's called directly as opposed by being imported by some other module.  &lt;/p&gt;
&lt;h2 id="making it executable"&gt;Making it executable&lt;/h2&gt;
&lt;p&gt;Lastly we want to mark our file "executable" so the operating system know it can actually call this file as a script or a program:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;chmod +x ~/bin/amicool&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And there we go! Your script is good to go and whenever you feel inadequate regarding your coolness just type:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ amicool
Yes you are, keep it up!
&lt;/pre&gt;&lt;/div&gt;</content><category term="code"></category><category term="python"></category><category term="linux"></category><category term="guide"></category></entry><entry><title>How to get scrapy help.</title><link href="https://granitosaurus.github.io/scrapy-help.html" rel="alternate"></link><published>2016-10-30T00:00:00+02:00</published><updated>2016-10-30T00:00:00+02:00</updated><author><name>Bernardas Ališauskas</name></author><id>tag:granitosaurus.github.io,2016-10-30:/scrapy-help.html</id><summary type="html">&lt;p&gt;Few suggestions how to ask questions correctly and where to ask them regarding using scrapy web-crawling framework.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Scrapy is a web-scraping framework for python. It's pretty popular and at the moment of writing it has over 16000 stars &lt;a href="https://github.com/scrapy/scrapy"&gt;on github&lt;/a&gt;. In terms of codebase scrapy is pretty simple, however there are few things that are not as explicit as they could be in favor of abstraction and development simplicity.&lt;br/&gt;
Not to mention millions of websites that provide their own unique scraping challenges.  &lt;/p&gt;
&lt;p&gt;So if you do end up not understanding something or encountering some of the few scrapy's quirks, how do you go about it?&lt;/p&gt;
&lt;h1 id="stackoverflow guidelines"&gt;Stackoverflow Guidelines&lt;/h1&gt;
&lt;p&gt;First thing you should do is read is &lt;a href="http://stackoverflow.com/help/how-to-ask"&gt;&lt;em&gt;how to ask a good question on stackoverflow&lt;/em&gt;&lt;/a&gt;. &lt;br/&gt;
It's a brilliant guide by, without a doubt the biggest Q&amp;amp;A website on the web, and it focuses on how to ask a good questions regardless of the topic. Following these guidelines not only make it easy for people to help you but also easy for you, yourself to formulate your question and understand the issue you are facing!&lt;/p&gt;
&lt;h1 id="where to get help?"&gt;Where To Get Help?&lt;/h1&gt;
&lt;p&gt;There are two places you can go to with your scrapy related questions and issues:  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://stackoverflow.com/questions/tagged/scrapy"&gt;Stackoverflow&lt;/a&gt;. &lt;br/&gt;
The issue with Stackoverflow is that it has a general rule of questions having to be generic, that means asking how to get price on this item on amazon is not a fit question. However the user base on &lt;code&gt;scrapy&lt;/code&gt; tag seems to be quite understanding of this and tend to be quite lenient with reports and down-votes, but don't be surprised if your post gets down-voted or put on hold. All you can do is to try and make your issue more generic and hope for the best!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;IRC! @ irc.freenode.org #scrapy &lt;br/&gt;
Good old IRC has been there for decades and even though it dropped in popularity quite significantly, it's still a great place to get help on any subject and scrapy is not an exception. 
Feel free to join the channel and ask questions about anything scrapy related; you can find me there too!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://support.scrapinghub.com/forums/1-general/"&gt;Scrapinghub Forums&lt;/a&gt;&lt;br/&gt;
Scrapinghub is the company behind scrapy and they have a user forum, so naturally it's a great place to look for help when it comes to your scrapy issues!  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reddit&lt;br/&gt;
There's an official &lt;a href="https://reddit.com/r/scrapy"&gt;scrapy subreddit&lt;/a&gt;, which isn't very active but I can tell you for a fact that a lot of people that are involved with scrapy keep an eye on it. It's a great place for some discussions that might not fit stackoverflow and irc.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="providing information"&gt;Providing Information&lt;/h1&gt;
&lt;p&gt;To debug an issue and get the help you need you need to provide information about your problem:  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Source Code of your spider, settings.py and pipelines.py files.&lt;/li&gt;
&lt;li&gt;Website you are crawling - sometimes people refrain from providing the url in fear of legal issues or some judgment. Don't worry about that, scraping is very much legal and no one will judge you, it might very well be the opposite - people might be more keen to help you scrape some weird porn website than amazon.  &lt;/li&gt;
&lt;li&gt;Crawl Log (see &lt;a href="#log"&gt;Producing Logs&lt;/a&gt;) - Scrapy logs majority of the events that happen in your spider, so to debug your spider the best resources are these logs.  &lt;/li&gt;
&lt;li&gt;Spider Output (see &lt;a href="#output"&gt;Producing Output&lt;/a&gt;) - This will rarely be useful for anyone else but yourself, but it can be very useful in some cases.  &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Once you have these bits you can easily formulate your question and I'm sure someone will help you out!&lt;/p&gt;
&lt;h2 id="log"&gt;Producing Logs&lt;/h2&gt;
&lt;p&gt;To save a log of your spider run you can use UNIX output redirection syntax:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;scrapy crawl myspider 2&amp;gt;&amp;amp;1 &amp;gt; mylog.log&lt;/span&gt;
&lt;span class="err"&gt;# or&lt;/span&gt;
&lt;span class="err"&gt;scrapy crawl myspider &amp;amp;&amp;gt; mylog.log&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Explanation:&lt;br/&gt;
    1. &lt;code&gt;scrapy crawl myspider&lt;/code&gt; - is a scrapy command that will start crawling spider called &lt;code&gt;myspider&lt;/code&gt;&lt;br/&gt;
    2. &lt;code&gt;2&amp;gt;&amp;amp;1&lt;/code&gt; - is UNIX syntax for redirecting error output to standard output. In UNIX there are types of outputs and in your log you want to have both of them in one file.&lt;br/&gt;
    3. &lt;code&gt;&amp;gt; mylog.log&lt;/code&gt; - is another UNIX output redirection, but this time we redirect the output to file called &lt;code&gt;mylog.log&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Tip: points 2 and 3 can be summarized as &lt;code&gt;&amp;amp;&amp;gt;&lt;/code&gt; in bash version 4 and up&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;For logging scrapy uses python's built-in &lt;a href="https://docs.python.org/3/library/logging.html"&gt;&lt;code&gt;logging&lt;/code&gt; module&lt;/a&gt; which by itself is pretty awesome! If you look into it, it might appear quite daunting but you can actually just &lt;code&gt;import logging&lt;/code&gt; and simply log message to root logger: &lt;code&gt;logging.warning("this page has no next page")&lt;/code&gt;. To have simple logging in your spider.&lt;/p&gt;
&lt;h2 id="output"&gt;Producing Output&lt;/h2&gt;
&lt;p&gt;Scrapy can automatically produce output in one these formats:  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;'xml', 'jsonlines', 'jl', 'json', 'csv', 'pickle', 'marshal'&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To do that simply run &lt;code&gt;crawl&lt;/code&gt; command with &lt;code&gt;--output&lt;/code&gt; flag (&lt;code&gt;-o&lt;/code&gt; for short version) and provide a name + file ending of format you want as an argument:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;scrapy crawl myspider --output output.json&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;em&gt;This will output all items your spider spews out to &lt;code&gt;output.json&lt;/code&gt; file.&lt;/em&gt; &lt;/p&gt;
&lt;p&gt;To get help for readability purposes you probably want to use either &lt;code&gt;json&lt;/code&gt; or &lt;code&gt;xml&lt;/code&gt; since those are most readable and as described in section below parsing-friendly formats.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Tip: You can actually tell scrapy to produce output to stdout directly by setting output argument to &lt;code&gt;-&lt;/code&gt;:&lt;/em&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;scrapy crawl myspider -t json -o - output.json&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="inspecting output"&gt;Inspecting Output&lt;/h2&gt;
&lt;p&gt;There few tools to parse &lt;code&gt;json&lt;/code&gt; or &lt;code&gt;xml&lt;/code&gt; content, similar like you'd use &lt;code&gt;sed&lt;/code&gt; or &lt;code&gt;grep&lt;/code&gt; in unix. The most popular and widely known is probably &lt;a href="https://stedolan.github.io/jq/"&gt;jq&lt;/a&gt;, which I believe translates to json query.&lt;br/&gt;
I personally really dislike that jq uses it's own mini-language as opposed to xpath or css selectors we all know, love and use daily.&lt;br/&gt;
So in response to this I made &lt;a href="https://github.com/granitosaurus/pq/"&gt;&lt;strong&gt;PQ&lt;/strong&gt;&lt;/a&gt;! It uses xpath and css selectors as well as support both json and xml parsing.&lt;/p&gt;
&lt;p&gt;To put it shortly, using the tools described above you can find specific values of some fields really easily.&lt;br/&gt;
Lets imagine we have a bunch of products that have these fields: name and price. Now for some reason Samsung items have weird pricing and we want to find out whether that's the case every time we update the code. &lt;/p&gt;
&lt;p&gt;For example using pq we can navigate the prices of items that have some keywords in their names:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;cat output.json | pq "//item[contains(@name,'samsung')]/price/text()"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Will find all items that contain "samsung" in the name and output their price values. If you change up your spider an run this command again you can easily navigate whether the values are changing.&lt;/p&gt;
&lt;p&gt;You can combine this with scrapy spider redirection to have everything in one line:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;scrapy crawl spider --nolog -t json -o - | pq "//item[contains(@name,'samsung')]/price/text()"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h1 id="conclusion_1"&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Scrapy is a lovely framework and web-crawling is a tricky subjects with a lot of hidden issues, quirks and complexities. Because of it being rather big subjects and every spider having it's own challenges it might be difficult to find help. However I feel if you follow the steps and ideas described in this blog post you'll have a really good chance at getting some help either on stackoverflow or irc!&lt;/p&gt;
&lt;p&gt;Do you have any places where you go to with your scrapy or web-crawling related questions? Did I miss something important? Leave the comment below :)&lt;/p&gt;</content><category term="code"></category><category term="scrapy"></category><category term="python"></category><category term="stackoverflow"></category><category term="web-crawling"></category></entry><entry><title>How to parse complicated json trees.</title><link href="https://granitosaurus.github.io/crawling-json.html" rel="alternate"></link><published>2016-10-10T00:00:00+02:00</published><updated>2016-10-10T00:00:00+02:00</updated><author><name>Bernardas Ališauskas</name></author><id>tag:granitosaurus.github.io,2016-10-10:/crawling-json.html</id><summary type="html">&lt;p&gt;Often when web-crawling you can find access to website's api which provides direct JSON of a product, however it's not always so easy to find what you need in what could be a multi-layer mess of a json.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Often when web-crawling you can find access to website's api which provides direct JSON of a product, however it's not always so easy to find what you need in what could be a multi-layer mess of a json.&lt;/p&gt;
&lt;p&gt;In this blog-post I'll cover few tools and ways to deal with really ugly json trees that you probably don't want to iterate through manually using dictionary key indices.&lt;br/&gt;
&lt;strong&gt;If you don't care about the research you can just skip to the &lt;a href="#right"&gt;right tool&lt;/a&gt; and &lt;a href="#solving"&gt;solving of the real life case&lt;/a&gt; sections at the end&lt;/strong&gt;.&lt;/p&gt;
&lt;h1 id="cause"&gt;Cause&lt;/h1&gt;
&lt;p&gt;Often websites, especially the ones that sell various products tend to overcomplicate their apis by stacking everything in one huge json tree that is at least 10 layers deep and is impossible to understand for an outsider or maybe even other developers in the company.&lt;/p&gt;
&lt;p&gt;In this case we'll take a look at small examples of &lt;a href="http://ah.nl"&gt;http://ah.nl&lt;/a&gt; responses and how can we deal with them without spending hours trying to reverse engineer the whole process.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example info&lt;/strong&gt;:&lt;br/&gt;
Product url: &lt;a href="http://www.ah.nl/producten/product/wi166580/maggi-opkikker-rundvlees"&gt;http://www.ah.nl/producten/product/wi166580/maggi-opkikker-rundvlees&lt;/a&gt;&lt;br/&gt;
Product api response: &lt;a href="https://ptpb.pw/aZ_S"&gt;https://ptpb.pw/aZ_S&lt;/a&gt;&lt;br/&gt;
If you put this response through some json visual tool like &lt;a href="http://jsonviewer.stack.hu/"&gt;http://jsonviewer.stack.hu/&lt;/a&gt; you'll notice what a huge mess it is: &lt;/p&gt;
&lt;p&gt;&lt;img alt="example json view" src="https://granitosaurus.github.io/images/json-crawling.png"/&gt;&lt;/p&gt;
&lt;p&gt;Multiple layers, multiple elements, list in a dict in a list in a dict and to parse that you'd end up doing something like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;json&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loads&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;body&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;items&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'_embedded'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'lanes'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'_embedded'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'items'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And that's just half-way through the tree. For example to find the sku you'd have to use something like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;sku = data['_embedded']['lanes'][4]['_embedded']['items'][0]['_embedded']['product']['id']&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now that's with hard-coding of list indices which are very likely to change for every product, so on top of that ugly line above you'd have to use multiple list comprehensions to find the correct list item from the &lt;code&gt;lanes&lt;/code&gt; or &lt;code&gt;items&lt;/code&gt; lists.  This is bad, ugly, unreliable and extremely painful to work with.&lt;/p&gt;
&lt;h1 id="tools to solve this"&gt;Tools to Solve This&lt;/h1&gt;
&lt;p&gt;There are several ways this can be approaches and let me spoil it for you, majority of them are bad, so we'll start off with those.&lt;/p&gt;
&lt;p&gt;To demonstrate these tools better we'll be parsing this simple json:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;data = """{&lt;/span&gt;
&lt;span class="err"&gt;    "one": {&lt;/span&gt;
&lt;span class="err"&gt;        "two": [{&lt;/span&gt;
&lt;span class="err"&gt;            "four": {&lt;/span&gt;
&lt;span class="err"&gt;                "name": "four1_name"&lt;/span&gt;
&lt;span class="err"&gt;            }&lt;/span&gt;
&lt;span class="err"&gt;        }, {&lt;/span&gt;
&lt;span class="err"&gt;            "four": {&lt;/span&gt;
&lt;span class="err"&gt;                "name": "four2_name"&lt;/span&gt;
&lt;span class="err"&gt;            }&lt;/span&gt;
&lt;span class="err"&gt;        }]&lt;/span&gt;
&lt;span class="err"&gt;    }&lt;/span&gt;
&lt;span class="err"&gt;}"""&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;All examples below are also available on iPython notebook if you want to mess around with them yourself &lt;a href="https://granitosaurus.github.io/data/crawling-json_examples.ipynb"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="wrong: flattening the json"&gt;Wrong: Flattening The Json&lt;/h2&gt;
&lt;p&gt;At first glance this might appear as an obvious solution - just flatten everything to the first level! However this brings out a huge issue with keys. Because every key has to be unique, when flattening the dictionary you need to merge several keys into one to preserve the tree order.
If we were to flatten our &lt;code&gt;data&lt;/code&gt;, it would end up looking like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;data = """{&lt;/span&gt;
&lt;span class="err"&gt;    "one_two_four1_name": "four1_name",&lt;/span&gt;
&lt;span class="err"&gt;    "one_two_four2_name": "four2_name",&lt;/span&gt;
&lt;span class="err"&gt;    }"""&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In a way you might think it looks nice, but the truth is that it's really unpredictable and hard to parse in a more complex context, since you can only select individual values. This might be useful for some edge cases where you only need 1 field the json tree is only two or tree levels deep, but otherwise it's not worth bothering with.&lt;/p&gt;
&lt;h2 id="wrong: jmespath, jsonpath and jsoniq etc."&gt;Wrong: Jmespath, JSONPath and JSONiq etc.&lt;/h2&gt;
&lt;p&gt;These few libraries in a way designed specifically to solve this issue. It seems that json is notoriously bad when it comes to this issue, so tools like theses are dime a dozen on github and while they are great, they fall short when in comes to web-crawling or similar use cases.   &lt;/p&gt;
&lt;p&gt;However there are two major issues with these tools:  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;First one being that some of them like the very &lt;code&gt;Jmespath&lt;/code&gt;'s &lt;strong&gt; expressions root-bound&lt;/strong&gt; which means non-rooted expressions like xpath's &lt;code&gt;//product/name&lt;/code&gt; are not possible. This means that you need to write this ugly chain which is barely different to our dict key indices one:&lt;/p&gt;
&lt;p&gt;root.foo.bar[].foo2.bar2.product.mynode&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The only improvement here is that we can do a bit of recursion by calling &lt;code&gt;[]&lt;/code&gt; for every list element, saving us a few list comprehension calls. And it definitely looks nicer, doesn't it?&lt;br/&gt;
It is still bad though since at any point the tree might change and our crawler will break because we are root bound.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The second issue being is that all of them &lt;strong&gt;are extremely bloated&lt;/strong&gt;, to the point where they not only design their own parsing logic but also design their own syntax.   &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When you are crawling a website you already have your own parsing tools to parse the html/xml (like &lt;code&gt;lxml&lt;/code&gt; or &lt;code&gt;parsel&lt;/code&gt;) and anything other would just introduce obvious redundancy and unnecessary complexity. &lt;/p&gt;
&lt;h2 id="almost right: js2xml"&gt;Almost Right: js2xml&lt;/h2&gt;
&lt;p&gt;First I'd like to start off with and give a shout out to a great tool called &lt;code&gt;js2xml&lt;/code&gt; which maintained by Scrapinghub. It pretty much does what it says - converts javascript code to an xml tree and it's &lt;em&gt;almost&lt;/em&gt; the right tool for our issue, almost.&lt;br/&gt;
Since json is part of javascript, this means we can use this tool to parse it:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;lxml&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;etree&lt;/span&gt;
&lt;span class="c1"&gt;# we need to wrap our data json in variable declaration&lt;/span&gt;
&lt;span class="c1"&gt;# for js2xml to interpret it&lt;/span&gt;
&lt;span class="n"&gt;parsed&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;js2xml&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'var foo = '&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;etree&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tostring&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;parsed&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pretty_print&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This is the result:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;&amp;lt;program&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;var&lt;/span&gt; &lt;span class="na"&gt;name=&lt;/span&gt;&lt;span class="s"&gt;"foo"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;object&amp;gt;&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;lt;property&lt;/span&gt; &lt;span class="na"&gt;name=&lt;/span&gt;&lt;span class="s"&gt;"one"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;object&amp;gt;&lt;/span&gt;
          &lt;span class="nt"&gt;&amp;lt;property&lt;/span&gt; &lt;span class="na"&gt;name=&lt;/span&gt;&lt;span class="s"&gt;"two"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;array&amp;gt;&lt;/span&gt;
              &lt;span class="nt"&gt;&amp;lt;object&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;property&lt;/span&gt; &lt;span class="na"&gt;name=&lt;/span&gt;&lt;span class="s"&gt;"four"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
                  &lt;span class="nt"&gt;&amp;lt;object&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;property&lt;/span&gt; &lt;span class="na"&gt;name=&lt;/span&gt;&lt;span class="s"&gt;"name"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
                      &lt;span class="nt"&gt;&amp;lt;string&amp;gt;&lt;/span&gt;four1_name&lt;span class="nt"&gt;&amp;lt;/string&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
                  &lt;span class="nt"&gt;&amp;lt;/object&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
              &lt;span class="nt"&gt;&amp;lt;/object&amp;gt;&lt;/span&gt;
              &lt;span class="nt"&gt;&amp;lt;object&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;property&lt;/span&gt; &lt;span class="na"&gt;name=&lt;/span&gt;&lt;span class="s"&gt;"four"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
                  &lt;span class="nt"&gt;&amp;lt;object&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;property&lt;/span&gt; &lt;span class="na"&gt;name=&lt;/span&gt;&lt;span class="s"&gt;"name"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
                      &lt;span class="nt"&gt;&amp;lt;string&amp;gt;&lt;/span&gt;four2_name&lt;span class="nt"&gt;&amp;lt;/string&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
                  &lt;span class="nt"&gt;&amp;lt;/object&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
              &lt;span class="nt"&gt;&amp;lt;/object&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;/array&amp;gt;&lt;/span&gt;
          &lt;span class="nt"&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;/object&amp;gt;&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;/object&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;/var&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/program&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As you can see it works and could probably be parsed with xpath. It's really ugly and if we were to write an xpath for it, it would be unnecessary complicated and long, but it would work! &lt;br/&gt;
If you are already using it to parse javascript somewhere you might just go with it to reduce dependencies if you wish so.&lt;/p&gt;
&lt;h1 id="right_1"&gt;Right: Converting json to xml and Parsing It With xpath&lt;/h1&gt;
&lt;p&gt;I found two tools and either one of them combined with either &lt;a href="http://lxml.de/"&gt;&lt;code&gt;lxml&lt;/code&gt;&lt;/a&gt; or &lt;a href="https://github.com/scrapy/parsel"&gt;&lt;code&gt;parsel&lt;/code&gt;&lt;/a&gt; selectors create this beautiful, perfect json-crawling combo for your crawler! &lt;/p&gt;
&lt;p&gt;For unaware &lt;code&gt;lxml&lt;/code&gt; is a really great tool for parsing xml and html while &lt;code&gt;parsel&lt;/code&gt; is built on top of it to make it even greater, so I highly recommend checking it out!
Fun fact - it's also used by &lt;a href="https://github.com/scrapy/scrapy"&gt;scrapy&lt;/a&gt; and that's where it originated.&lt;/p&gt;
&lt;p&gt;Getting back to the point, the two tools that are pretty much alternative to each other are &lt;a href="https://github.com/quandyfactory/dicttoxml"&gt;&lt;code&gt;dicttoxml&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://github.com/delfick/python-dict2xml"&gt;&lt;code&gt;dict2xml&lt;/code&gt;&lt;/a&gt;. They are essentially the same thing but I thought I'd mention both since I'm not sure which one is better and requires the recognition. &lt;br/&gt;
For sake of being brief I'll show off &lt;code&gt;dicttoxml&lt;/code&gt; + &lt;code&gt;parsel&lt;/code&gt; only:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;dicttoxml&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;dicttoxml&lt;/span&gt;
&lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dicttoxml&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loads&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;attr_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# the tree we get:&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;one&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;two&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
      &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;four&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
          &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;four1_name&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;four&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
      &lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
      &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;four&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
          &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;four2_name&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;four&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
      &lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;two&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;one&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now we can parse this tree using &lt;code&gt;parsel.Selector&lt;/code&gt; and xpath:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;parsel&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Selector&lt;/span&gt;
&lt;span class="n"&gt;sel&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Selector&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'utf-8'&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="c1"&gt;# and get the names with&lt;/span&gt;
&lt;span class="n"&gt;sel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"//name/text()"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extract&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="c1"&gt;# ['four1_name', 'four2_name']&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Pretty mind blowing how we solved this mess with one 300 loc big package from pypi and one short xpath.&lt;/p&gt;
&lt;h1 id="solving"&gt;Solving Our Example&lt;/h1&gt;
&lt;p&gt;Now that we have chosen a tool let's see how well it works on a real life example we got ourselves at the beginning of this blog: &lt;a href="http://www.ah.nl/producten/product/wi166580/maggi-opkikker-rundvlees"&gt;http://www.ah.nl/producten/product/wi166580/maggi-opkikker-rundvlees&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;I'm going to spoil you the joy of reverse engineering the products api and tell you the api url in this case is: 
&lt;code&gt;'http://www.ah.nl/service/rest/delegate?url=/producten/product/wi166580/x'&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Lets assume we already have the page source in &lt;code&gt;body&lt;/code&gt; variable and dive in:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;dicttoxml&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;dicttoxml&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;parsel&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Selector&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;json&lt;/span&gt;

&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loads&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;body&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;sel&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Selector&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;dicttoxml&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attr_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="c1"&gt;# now we can find things very easily!&lt;/span&gt;
&lt;span class="c1"&gt;# sku:&lt;/span&gt;
&lt;span class="n"&gt;sel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"//product/id/text()"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extract&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="c1"&gt;# [u'wi166580']&lt;/span&gt;
&lt;span class="c1"&gt;# price:&lt;/span&gt;
&lt;span class="n"&gt;sel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"//product//pricelabel/now/text()"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extract&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="c1"&gt;# [u'0.82']&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h1 id="conclusion"&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Mission accomplished! We managed to parse multi-layer monster with very few, simple xpaths and a small package from pipy!&lt;br/&gt;
Personally I wish I started doing this earlier because iterating through monsters like this one key at the time is extremely tedious and it breaks every time the website decides to update something. &lt;br/&gt;
Hopefully this write up can save someone few hours and an early balding. :D&lt;/p&gt;</content><category term="code"></category><category term="python"></category><category term="web-crawling"></category><category term="scrapy"></category></entry><entry><title>First post. Hello Pelican!</title><link href="https://granitosaurus.github.io/installing-pelican.html" rel="alternate"></link><published>2016-10-09T00:00:00+02:00</published><updated>2016-10-09T00:00:00+02:00</updated><author><name>Bernardas Ališauskas</name></author><id>tag:granitosaurus.github.io,2016-10-09:/installing-pelican.html</id><summary type="html">&lt;p&gt;Starting up the blog with Python and Pelican static blog generator!&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've decided to start a blog after Python package called Pelican caught my eye.&lt;br/&gt;
Pelican is a tool to generate a static blog from reStructuredText or Markdown input files. And most importantly it looks to be really fun, full python with jinja2 templating, which means it's fully extendable, configurable and modifiable as it's under GPL license.&lt;/p&gt;
&lt;h3 id="installing pelican"&gt;Installing Pelican&lt;/h3&gt;
&lt;p&gt;&lt;img alt="Pelicans are cool" src="https://granitosaurus.github.io/images/pelican-bird.jpg"/&gt;&lt;br/&gt;
The setup for &lt;code&gt;Pelican&lt;/code&gt; is pretty straightforward just run:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;~&amp;gt; pip install pelican  &lt;span class="c1"&gt;# Installing Pelican package for python&lt;/span&gt;
~&amp;gt; mkdir blog &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nb"&gt;cd&lt;/span&gt; blog  &lt;span class="c1"&gt;# Create and jump into your blog directory!&lt;/span&gt;
~/blog/&amp;gt; pelican-quickstart
    ... &lt;span class="c1"&gt;#answer some simple questions here&lt;/span&gt;
~/blog/&amp;gt; vim content/first-page.md
    ... &lt;span class="c1"&gt;#write your blog here in simple markdown&lt;/span&gt;
~/blog/&amp;gt; pelican content  &lt;span class="c1"&gt;# regenerate website&lt;/span&gt;
~/blog/&amp;gt; &lt;span class="nb"&gt;cd&lt;/span&gt; output
~/blog/output&amp;gt; python -m pelican.server  &lt;span class="c1"&gt;# run pelican server to test locally&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now connect to &lt;code&gt;http://localhost:8000&lt;/code&gt; and there you go!&lt;br/&gt;
You can check &lt;a href="http://docs.getpelican.com/en/latest/content.html#articles-and-pages"&gt;here&lt;/a&gt; for how to template your message how to format your blog entry.&lt;/p&gt;
&lt;h3 id="vim markdown highlight for .md files"&gt;Vim markdown highlight for .md files&lt;/h3&gt;
&lt;p&gt;While going through the installation I've noticed that markdown doesn't have highlighting in vim which was peculiar. I found &lt;a href="http://superuser.com/questions/701496/no-syntax-highlight-on-md-files"&gt;this post which describes a simple fix&lt;/a&gt;.&lt;br/&gt;
Simply create directories and file: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;~/.vim/ftdetect/markdown.vim&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;with content: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;au BufNewFile,BufRead *.md  setf markdown&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="theming pelican"&gt;Theming Pelican&lt;/h3&gt;
&lt;p&gt;The default Pelican theme is pretty great however I stumbled on &lt;a href="https://github.com/alexandrevicenzi/Flex"&gt;flex-theme&lt;/a&gt; on &lt;a href="https://github.com/getpelican/pelican-themes"&gt;pelican theme repo&lt;/a&gt; on github. So that's my choice for now, but I'd like to touch up the color scheme a bit. Check out &lt;a href="http://docs.getpelican.com/en/stable/pelican-themes.html"&gt;&lt;code&gt;pelican-themes&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="configuring pelican"&gt;Configuring Pelican&lt;/h3&gt;
&lt;p&gt;A lot of bells and whistles come straight out of the box with the pelican and your theme. For example to setup Disqus commnets all I had to do is add &lt;code&gt;DISQUS_SITENAME = "granitosaurus"&lt;/code&gt; where &lt;code&gt;granitosaurus&lt;/code&gt; is my registered name of my disqus account.&lt;/p&gt;
&lt;h3 id="publishing pelican"&gt;Publishing Pelican&lt;/h3&gt;
&lt;p&gt;Since Pelican generates a static webpage you can use anything to publish it. I decided to use &lt;a href="http://docs.getpelican.com/en/stable/tips.html#user-pages"&gt;github user pages&lt;/a&gt; which is a bit more complicated than the docs make it out to be. For user pages I like to keep the whole source code in branch &lt;code&gt;source&lt;/code&gt; and keep the generated output in &lt;code&gt;master&lt;/code&gt; as per github's user pages rule. Then use &lt;code&gt;ghp-import&lt;/code&gt; to automatically update master code with the most recent  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt; &lt;span class="n"&gt;git&lt;/span&gt; &lt;span class="n"&gt;checkout&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="n"&gt;source&lt;/span&gt;
&lt;span class="err"&gt;$&lt;/span&gt; &lt;span class="n"&gt;pelican&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;o&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="n"&gt;publishconf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;
&lt;span class="err"&gt;$&lt;/span&gt; &lt;span class="n"&gt;ghp&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;output&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="n"&gt;master&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The above will make source branch, generate blog and push the output to &lt;code&gt;master&lt;/code&gt; so it's viewable at https://username.github.io &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt; The most important bit is to set &lt;code&gt;SITEURL&lt;/code&gt; in your &lt;code&gt;publishconf.py&lt;/code&gt; to &lt;code&gt;https://username.github.io&lt;/code&gt; make sure it's &lt;strong&gt;HTTPS&lt;/strong&gt; since default SITEURL generated by pelican is http and github pages requires https. This took me an hour of messing around to finally figure out.&lt;/p&gt;
&lt;h3 id="wrap up"&gt;Wrap Up&lt;/h3&gt;
&lt;p&gt;So far Pelican took quite a bit of work to get things going. It looks quite simple but there's a bunch of little quirks that are really hard to debug. It's not as easy as starting up a wordpress blog but it's quite fun and it seems to be really flexible. &lt;br/&gt;
Let's see if it pays off! &lt;/p&gt;
&lt;p&gt;Checkout the source for more at https://github.com/Granitas/granitas.github.io/tree/source&lt;/p&gt;</content><category term="code"></category><category term="pelican"></category><category term="python"></category><category term="blog"></category></entry></feed>